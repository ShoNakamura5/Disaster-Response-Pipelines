# Disaster Response Pipeline Project

## Installation <a name="installation"></a>

This project requires Python 3.* and the following Python libraries installed:

1.nltk　　
2.re　　
3.numpy
4.pandas
5.pickle
6.sqlite3
7.sqlalchemy
8.sys
9.sklearn
10.json
11.plotly
12.flask

## Project Motivation<a name="motivation"></a>

The purpose of this project is to create a web application to classify disaster messages. This application will categorize them into categories and let people know what kind of assistance they need.

## File Descriptions <a name="files"></a>

- process_data.py: messages.csv and categories.csv and creates an SQLite database containing a merged and cleaned version of this data.
- train_classifier.py: The database generated by process_data.py is used as input and the data in it is used to create an ML model for classifying messages.
- ETL Pipeline Preparation.ipynb: The process of creating process_data.py.
- ML Pipeline Preparation.ipynb: The process of creating train_classifier.py.
-  disaster_messages.csv, disaster_categories.csv contain sample messages (real messages that were sent during disaster events) and categories datasets in csv format.
-  templates folder: This folder contains all of the files necessary to run and render the web app.

### Instructions:
1. Run the following commands in the project's root directory to set up your database and model.

    - To run ETL pipeline that cleans data and stores in database
        `python data/process_data.py data/disaster_messages.csv data/disaster_categories.csv data/DisasterResponse.db`
    - To run ML pipeline that trains classifier and saves
        `python models/train_classifier.py data/DisasterResponse.db models/classifier.pkl`

2. Go to `app` directory: `cd app`

3. Run your web app: `python run.py`

4. Click the `PREVIEW` button to open the homepage
